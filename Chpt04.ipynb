{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.5 1.5]\n",
      " [1.5 1.5]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "The values in the tensor\n",
      "[[1.5 1.5]\n",
      " [1.5 1.5]]\n",
      "\n",
      "tensor2\n",
      " tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(2, 4), dtype=float64)\n",
      "\n",
      "The values in tensor2\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tensor1=tf.convert_to_tensor(1.5*np.ones((2,2)),dtype=tf.float32) # we specify the dtype in the convert_to_tensor() method\n",
    "print(tensor1)\n",
    "print(\"\\nThe values in the tensor\")\n",
    "print(tensor1.numpy())\n",
    "\n",
    "tensor2=tf.convert_to_tensor(np.zeros((2,4)))\n",
    "print('\\ntensor2\\n',tensor2)\n",
    "print('\\nThe values in tensor2\\n',tensor2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor1\n",
      " tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "\n",
      "the values in tensor1\n",
      " [1 2]\n",
      "\n",
      " tensor2\n",
      " tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "\n",
      " the values of tensor2\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "\n",
      " tensor3\n",
      " tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "\n",
      " the values of tensor3\n",
      " [[1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "tensor1=tf.convert_to_tensor([1,2])\n",
    "print('\\ntensor1\\n',tensor1)\n",
    "print('\\nthe values in tensor1\\n',tensor1.numpy())\n",
    "\n",
    "tensor2=tf.convert_to_tensor([[1,2],[3,4]])\n",
    "print('\\n tensor2\\n',tensor2)\n",
    "print('\\n the values of tensor2\\n',tensor2.numpy())\n",
    "\n",
    "tensor3=tf.convert_to_tensor([[1],[2]])\n",
    "print('\\n tensor3\\n',tensor3)\n",
    "print('\\n the values of tensor3\\n',tensor3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将tensor初始化全部为零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 初始化为一个scalar 0\n",
    "tensor1=tf.zeros([])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个vector 0\n",
    "tensor2=tf.zeros([1])# 1 表示shape\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor3=tf.zeros_like(tensor3) # create a zero tensor based on the previously tensor3\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将tensor全部初始化为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个scalar 1\n",
    "tensor1=tf.ones([])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个向量1\n",
    "tensor2=tf.ones([2])\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [1]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个ones_like\n",
    "tensor3=tf.ones_like(tensor3)\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor1=tf.fill([3,4],3.0)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal利用正态分布初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47074926  0.806013    3.4872637 ]\n",
      " [ 1.9491398  -1.2811301   0.75439274]]\n"
     ]
    }
   ],
   "source": [
    "tensor1=tf.random.normal([2,3],mean=1,stddev=1)\n",
    "print(tensor1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33490542  0.8289524  -0.7614883 ]\n",
      " [ 0.26193872  0.67142373 -0.19508004]]\n"
     ]
    }
   ],
   "source": [
    "tensor1=tf.random.normal([2,3]) # 未指定参数，按照标准正态分布产生\n",
    "print(tensor1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36331737  1.2414317  -0.2524041 ]\n",
      " [ 0.32557806  1.0882075   0.3530345 ]]\n"
     ]
    }
   ],
   "source": [
    "# tf.random.truncated_normal 截断正态分布，当数据大于某个值时，重新采样，防止生成的有的sample 距离中心太远\n",
    "tensor2=tf.random.truncated_normal([2,3])\n",
    "print(tensor2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform 利用均匀分布初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04177165 0.45704508 0.7888428 ]\n",
      " [0.33540547 0.23157287 0.68474686]]\n"
     ]
    }
   ],
   "source": [
    "tensor1=tf.random.uniform([2,3],minval=0,maxval=1)\n",
    "print(tensor1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64.42587   -0.2563529  3.3353648 54.858273 ]\n",
      " [21.343884  14.795409  36.894142  45.055805 ]\n",
      " [18.999464  64.08079   46.417076  51.958584 ]]\n"
     ]
    }
   ],
   "source": [
    "tensor2=tf.random.uniform([3,4],minval=-1,maxval=100)\n",
    "print(tensor2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## Random Permutation-- tf.random.shuffle\n",
    "idx=tf.range(10)\n",
    "print('idx',idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([6 0 3 1 5 2 7 9 4 8], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the idx\n",
    "shuffledIdx=tf.random.shuffle(idx)\n",
    "print(shuffledIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.random.truncated_normal([10,28,28,3],mean=128,stddev=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss 的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 4 samples belongs to 10 categories\n",
    "Xs=tf.random.truncated_normal([4,10]) #mean=0, stddev=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the actual labels for these 4 samples\n",
    "ys=np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot methods to generate lables\n",
    "y=tf.one_hot(ys,depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mse based on the tf.keras.losses.mse\n",
    "mse=tf.keras.losses.mse(Xs,y) # 表示每个样本的mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1791319, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#loss\n",
    "loss=tf.reduce_mean(mse) #表示所有样本的平均mse\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix 的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3723129  -0.3445495  -1.5297327  ... -0.10125105  0.95442164\n",
      "  -0.31371096]\n",
      " [ 0.35457274 -1.4406008   0.01184261 ... -0.12961417  1.2603388\n",
      "   1.3969551 ]\n",
      " [-0.50400126  0.49529934  0.3283863  ... -1.6665027  -1.5839794\n",
      "   0.8271543 ]\n",
      " [ 1.1912068   0.8059943   1.5361724  ...  1.9040502   1.4900529\n",
      "  -1.1007105 ]]\n"
     ]
    }
   ],
   "source": [
    "# generate 4 个28x28的图片，然后打平\n",
    "Xs=tf.random.truncated_normal([4,784])\n",
    "print(Xs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "denseLayer=tf.keras.layers.Dense(10)\n",
    "denseLayer.build((4,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将Xs转换为10个类别\n",
    "output=denseLayer(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48859018  0.02999738  1.6680865   0.1848881   0.18415484 -0.63987315\n",
      "   0.43685323 -0.5451695   0.02915066 -2.2275724 ]\n",
      " [ 0.3163087   0.83682144  0.48708466 -0.56299406  0.47148082  0.58217895\n",
      "   0.1167607   0.316918   -0.83765185 -0.5392237 ]\n",
      " [-1.5947502   0.6691804   0.5477969  -1.3548672  -1.6124613  -0.93344253\n",
      "  -0.0954574   1.6042051   0.21826443  0.12334912]\n",
      " [-0.6414008   1.2928023  -0.9172078  -1.2385048   0.07280216  2.4834504\n",
      "  -1.7627219  -0.4878604  -0.44336545  1.2332186 ]]\n"
     ]
    }
   ],
   "source": [
    "print(output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(denseLayer.bias.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05280245 -0.03019325  0.02043037 ... -0.07105641 -0.04426609\n",
      "  -0.04560211]\n",
      " [ 0.03138369  0.01584027  0.01358347 ... -0.07504599 -0.0389759\n",
      "   0.02871177]\n",
      " [-0.06796659 -0.02470696  0.06091861 ... -0.07530548 -0.01748697\n",
      "   0.06898249]\n",
      " ...\n",
      " [-0.05194361 -0.07345114  0.01165715 ...  0.04711678 -0.01214118\n",
      "   0.00355793]\n",
      " [ 0.02003109 -0.01493403 -0.05764304 ...  0.07448258 -0.07068512\n",
      "  -0.0868784 ]\n",
      " [ 0.05165536  0.06555247 -0.01674966 ... -0.05723902  0.02110045\n",
      "   0.0302215 ]]\n"
     ]
    }
   ],
   "source": [
    "print(denseLayer.kernel.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor 的索引与切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]], shape=(1, 5, 5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# basic indexing [][]\n",
    "a=tf.ones((1,5,5,3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(a[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(a[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(28, 3)\n",
      "tf.Tensor([-1.6009268   0.38413453  0.2426789 ], shape=(3,), dtype=float32)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "a=tf.random.normal([4,28,28,3])\n",
    "print(a[0].shape)\n",
    "print(a[1,2].shape) # 第二个图片的第3行\n",
    "print(a[1,2,3]) # 第二个图片，第3行，第4列 的元素\n",
    "print(a[1,2,3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([[[[0,1,2],[2,3,4]],[[5,6,7],[8,9,10]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(b[0][0][0]) #第一张图片的，第一行，第一列元素\n",
    "print(b[0][0][1]) #第一张图片的，第一行，第二列元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...采样方式：通常表示维度很多时，剩下所有的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个task的大小 (4, 28, 28, 3)\n",
      "另一种方法 (4, 28, 28, 3)\n",
      "另一种方法 (4, 28, 28, 3)\n",
      "输出红色通道的维度 (2, 4, 28, 28)\n",
      "另一种方法，输出红色通道的维度 (2, 4, 28, 28)\n",
      "输出第1个task的绿色通道的维度 (4, 28, 28)\n",
      "输出第1个task,第1个图片红色通道的维度 (28, 28)\n"
     ]
    }
   ],
   "source": [
    "a=tf.random.normal([2,4,28,28,3]) #有2个task,每个batch有4张图片，每个图片是28X28的3通道图像\n",
    "print('第一个task的大小',a[0].shape)\n",
    "print('另一种方法',a[0,:,:,:,:].shape)\n",
    "print('另一种方法',a[0,...].shape)\n",
    "print('输出红色通道的维度',a[:,:,:,:,0].shape)\n",
    "print('另一种方法，输出红色通道的维度',a[...,0].shape)\n",
    "print('输出第1个task的绿色通道的维度',a[0,...,1].shape)\n",
    "print('输出第1个task,第1个图片红色通道的维度',a[0,0,...,0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.gather 给出一个索引List,然后根据这个list来收集相应元素\n",
    "a=np.random.randint(0,100,size=(4,35,8)) # a 表示有4个班级的35个学生8门课的成绩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "classLvlGrade=tf.gather(a,axis=0,indices=[2,3]) # a表示数据源，axis表示所取数据的维度，axis=0表示要取班级维度，indices表示索取班级的编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 8)\n",
      "tf.Tensor(\n",
      "[[[73 68 44 63 56 82 50 69]\n",
      "  [33 19 61 21 49 38 78  3]\n",
      "  [29 99  8 57 87 50 75 60]\n",
      "  [89 50 64 21 48 12 97 17]\n",
      "  [ 9 64 69 56 71 46 18 15]]\n",
      "\n",
      " [[18  2 84 72 39 14 75 55]\n",
      "  [92 97 25 17 28 83 12 32]\n",
      "  [64 72 11 18 46 76 29 25]\n",
      "  [ 0 85  3  9 34 79 30 21]\n",
      "  [37 28 26 65 85 73 55  6]]\n",
      "\n",
      " [[ 8 37  2 79 85  1 97 23]\n",
      "  [ 4 97 78  0 22 78 10 46]\n",
      "  [56 51 29 30 27  5 88 63]\n",
      "  [88 71 42 19 64 10 27 15]\n",
      "  [95 22 42 90 47 81 79 58]]\n",
      "\n",
      " [[86 49 78 15 32 73 39 85]\n",
      "  [15 24 22 39 48 12 19 42]\n",
      "  [57 44 46 42 34 81  5 30]\n",
      "  [93  3 68 45 26 63 66 74]\n",
      "  [ 6 38  6 10 53 55 22 28]]], shape=(4, 5, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "studLvlGrade=tf.gather(a,axis=1,indices=[16,7,3,9,6]) #在每个班级内选取5个学生，查看成绩\n",
    "print(studLvlGrade.shape)\n",
    "print(studLvlGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 35, 3)\n"
     ]
    }
   ],
   "source": [
    "# 查看每个班级，每个学生的特定几门课的成绩\n",
    "CourseLvlGrade=tf.gather(a,axis=2,indices=[3,5,7])\n",
    "print(CourseLvlGrade.shape)\n",
    "# print(CourseLvlGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 8)\n",
      "tf.Tensor(\n",
      "[[[56 69 18]\n",
      "  [94 46 82]\n",
      "  [57  8 75]\n",
      "  [90  9 28]]\n",
      "\n",
      " [[65 26 55]\n",
      "  [19 46 32]\n",
      "  [18 11 29]\n",
      "  [43 61 46]]\n",
      "\n",
      " [[90 42 79]\n",
      "  [84 29 83]\n",
      "  [30 29 88]\n",
      "  [14 98 36]]\n",
      "\n",
      " [[10  6 22]\n",
      "  [58 35 55]\n",
      "  [42 46  5]\n",
      "  [20 58 85]]], shape=(4, 4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 如何对取特定的几个学生的特定几门课的成绩，用两个gather 串联起来，如第一个gather 取某几个学生在所有课程上的成绩，然后再在这个结果上应用另一个gather对课程操作\n",
    "studLvlGrade=tf.gather(a,axis=1,indices=[6,4,3,2]) #取编号为7，5，4，3的学生在所有课程上的成绩\n",
    "print(studLvlGrade.shape)\n",
    "courseStudLvlGrade=tf.gather(studLvlGrade,axis=2,indices=[3,2,6]) #取该4位学生在课程编号为4，3，7上的成绩\n",
    "print(courseStudLvlGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "tf.Tensor([89 50 64 21 48 12 97 17], shape=(8,), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor([11], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.gather_nd,能同时指定两个axis,返回这两个axis组合下的值\n",
    "# 如果想得到第一个班级里第10名学生的成绩\n",
    "stud10Grade=tf.gather_nd(a,[0,9])\n",
    "print(stud10Grade.shape)\n",
    "print(stud10Grade)\n",
    "#返回第二个班级里，第4个学生在第三门课上的成绩\n",
    "g=tf.gather_nd(a,[1,3,2])\n",
    "print(g)\n",
    "g1=tf.gather_nd(a,[[1,3,2]])\n",
    "print(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[57 99 55 57 22  2 19 68]\n",
      " [97 14 61 43 38 75 46 27]], shape=(2, 8), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[84 45  7 80 78 13 64 23]\n",
      " [26 32 97 92 58 45 66 16]\n",
      " [27 47 98 14  2  6 36 89]\n",
      " [57 44 46 42 34 81  5 30]], shape=(4, 8), dtype=int32)\n",
      "tf.Tensor([84 32 98 42], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 一次性返回第一个班级的第一个学生和第二班级的第3号学生在所有科目上的学习成绩\n",
    "g=tf.gather_nd(a,[[0,1],[1,2]])\n",
    "print(g)\n",
    "g=tf.gather_nd(a,[[0,0],[1,1],[2,2],[3,3]])\n",
    "print(g)\n",
    "g=tf.gather_nd(a,[[0,0,0],[1,1,1],[2,2,2],[3,3,3]])# 第1号班级第一号学生第一门课的成绩，依次类推。。。\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.boolean_mask 的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 28, 28, 3)\n",
      "(4, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 取出矩阵中特定的数\n",
    "a=tf.random.normal([4,28,28,3]) # 4 个28x28的彩色图像\n",
    "#取第一张和第三张图像\n",
    "a1=tf.boolean_mask(a,mask=[True,True,False,False])\n",
    "print(a1.shape)\n",
    "# 取所有图像的红色通道上的值\n",
    "a=tf.boolean_mask(a,mask=[True,False,False],axis=3) #mask 的长度必须对应于该轴的长度\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]], shape=(2, 3, 4), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.ones([2,3,4])\n",
    "print(a)\n",
    "print()\n",
    "print(tf.boolean_mask(a,mask=[[True,False,True],[False,True,False]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维度变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reshape(a,...)\n",
    "# tf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "a=tf.random.normal((4,3,2,1))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 3, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=844, shape=(4, 3, 1, 2), dtype=float32, numpy=\n",
       "array([[[[-1.0050664 , -0.7282231 ]],\n",
       "\n",
       "        [[ 1.4444928 ,  0.42903435]],\n",
       "\n",
       "        [[ 1.0758896 , -0.15058401]]],\n",
       "\n",
       "\n",
       "       [[[-1.4601474 , -0.13727722]],\n",
       "\n",
       "        [[-0.6990763 , -1.8261116 ]],\n",
       "\n",
       "        [[-1.215721  , -0.14686827]]],\n",
       "\n",
       "\n",
       "       [[[ 0.04413291, -1.2327082 ]],\n",
       "\n",
       "        [[-2.3393779 ,  0.9265482 ]],\n",
       "\n",
       "        [[-0.3005892 ,  0.9553196 ]]],\n",
       "\n",
       "\n",
       "       [[[ 1.6178818 ,  1.4105822 ]],\n",
       "\n",
       "        [[ 1.475668  , -0.00767523]],\n",
       "\n",
       "        [[-1.7058024 ,  1.0971006 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(a,perm=[0,1,3,2]) # 将axis=2 的数据和 axis=3的数据进行转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 35, 8)\n"
     ]
    }
   ],
   "source": [
    "# tf.expand_dim 增加一个维度, 如果axis 是正数就表示在该维度之前增加一个维度；如果axis是负数，表示在该维度之后增加一个维度\n",
    "a=np.random.randint(0,100,size=(4,35,8))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 35, 8)\n"
     ]
    }
   ],
   "source": [
    "# 在第0维之前增加一个维度\n",
    "a0=tf.expand_dims(a,axis=0)\n",
    "print(a0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 35, 8)\n"
     ]
    }
   ],
   "source": [
    "# 在第一维之前增加一个维度\n",
    "a1=tf.expand_dims(a,axis=1)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 35, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "# 在倒数第二维之后增加一个维度\n",
    "a2=tf.expand_dims(a,axis=-2)\n",
    "print(a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.squeeze 减少一个shape为1的维度\n",
    "tf.squeeze(a0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.zeros([1,2,1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=878, shape=(1, 2, 1, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当有多个 shape=1的维度时\n",
    "tf.squeeze(a)\n",
    "# 可以指定要删除维度的轴\n",
    "tf.squeeze(a,axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting: \n",
    "--表示将数据在某一维度上复制，但是没有真正在内存中复制；而tf.tile实现在内存中的复制（小维度对齐，只有一个数时，默认是小维度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.ones((2,3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a0=tf.broadcast_to(a,[2,2,3]) # 利用broadcast 扩张数据，但是内存上没有变化\n",
    "print(a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a1=tf.expand_dims(a,axis=0) #先增加一个维度\n",
    "print(a1)\n",
    "a2=tf.tile(a1,[2,1,1]) #再在相应维度上复制\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b=tf.fill([2,2],2.0)\n",
    "print(b)\n",
    "a=tf.ones((2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b= tf.Tensor(\n",
      "[[3. 3.]\n",
      " [3. 3.]], shape=(2, 2), dtype=float32)\n",
      "a-b= tf.Tensor(\n",
      "[[-1. -1.]\n",
      " [-1. -1.]], shape=(2, 2), dtype=float32)\n",
      "a*b= tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "a/b= tf.Tensor(\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# a+b\n",
    "c=a+b\n",
    "print('a+b=',c)\n",
    "\n",
    "# a-b\n",
    "c=a-b\n",
    "print('a-b=',c)\n",
    "\n",
    "# a*b\n",
    "c=a*b #element wise\n",
    "print('a*b=',c)\n",
    "\n",
    "#a/b\n",
    "c=a/b\n",
    "print('a/b=',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b//a= tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "b%a= tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# b//a 整除\n",
    "c=b//a\n",
    "print('b//a=',c)\n",
    "\n",
    "# b%a 取余\n",
    "c=b%a\n",
    "print('b%a=',c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_{3}= tf.Tensor(1.8927892, shape=(), dtype=float32)\n",
      "log_100(10)= tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# log--表示以e为底的对数\n",
    "# 求 log_8(3)\n",
    "c=tf.math.log(8.)/tf.math.log(3.)\n",
    "print('log_{3}=',c)\n",
    "\n",
    "# 求Log_100(10)\n",
    "c=tf.math.log(100.)/tf.math.log(10.)\n",
    "print('log_100(10)=',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b的3次方 tf.Tensor(\n",
      "[[8. 8.]\n",
      " [8. 8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#b的3次方\n",
    "c=tf.pow(b,3)\n",
    "print('b的3次方',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[8. 8.]\n",
      " [8. 8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(b**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.4142134 1.4142134]\n",
      " [1.4142134 1.4142134]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.sqrt(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02017205,  0.3835371 ,  0.05597138, -0.1287526 , -0.70844902,\n",
       "        0.45087574,  0.59559153, -0.35225331,  0.04402014,  0.00653837])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=972, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 0.65511507, -0.00633255, -0.16290481],\n",
       "       [-0.8425884 ,  1.118067  , -0.42477474]], dtype=float32)>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.truncated_normal([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
